Number of movements inside X_train: 41
Number of movements inside y_train: 41
X_train shape: torch.Size([40, 10, 8])
y_train shape: torch.Size([40, 8])

Single X_train tensor:
tensor([[-0.0402, -0.3652,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],
        [-0.0290, -0.3652,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],
        [ 0.0066, -0.3655,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825,  0.0123],
        [ 0.0480, -0.3656,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0481],
        [ 0.0895, -0.3652,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],
        [ 0.1310, -0.3650,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],
        [ 0.1724, -0.3649,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],
        [ 0.2139, -0.3648,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],
        [ 0.2554, -0.3648,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],
        [ 0.2969, -0.3648,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238]])

Corresponding y_train tensor:
tensor([ 0.3383, -0.3648,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238])
X_train tensor as table:
          x         y    z  roll  pitch       yaw  linear_velocity  \
0 -0.040197 -0.365190  0.0   0.0    0.0  0.153439         1.082531
1 -0.028958 -0.365195  0.0   0.0    0.0  0.153439         1.082531
2  0.006575 -0.365532  0.0   0.0    0.0  0.153439         1.082531
3  0.048038 -0.365624  0.0   0.0    0.0  0.153439         1.082531
4  0.089508 -0.365212  0.0   0.0    0.0  0.153439         1.082531
5  0.130979 -0.365017  0.0   0.0    0.0  0.153439         1.082531
6  0.172448 -0.364908  0.0   0.0    0.0  0.153439         1.082531
7  0.213917 -0.364838  0.0   0.0    0.0  0.153439         1.082531
8  0.255389 -0.364792  0.0   0.0    0.0  0.153439         1.082531
9  0.296858 -0.364766  0.0   0.0    0.0  0.153439         1.082531

   angular_velocity
0         -0.023835
1         -0.023835
2          0.012337
3         -0.048119
4         -0.023835
5         -0.023835
6         -0.023835
7         -0.023835
8         -0.023835
9         -0.023835

y_train tensor as table:
          x         y    z  roll  pitch       yaw  linear_velocity  \
0  0.338328 -0.364765  0.0   0.0    0.0  0.153439         1.082531

   angular_velocity
0         -0.023835
Number of movements inside X_val: 6
Number of movements inside y_val: 6
X_val shape: torch.Size([40, 10, 8])
y_val shape: torch.Size([40, 8])
Number of movements inside X_test: 6
Number of movements inside y_test: 6
X_test shape: torch.Size([40, 10, 8])
y_test shape: torch.Size([40, 8])
/home/samuele/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 6050). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() > 0
/home/samuele/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 1/110, Train Loss: 0.6475, Val Loss: 0.5031
Epoch 2/110, Train Loss: 0.4940, Val Loss: 0.4269
Epoch 3/110, Train Loss: 0.4047, Val Loss: 0.3364
Epoch 4/110, Train Loss: 0.3120, Val Loss: 0.3021
Epoch 5/110, Train Loss: 0.2564, Val Loss: 0.2708
Epoch 6/110, Train Loss: 0.2450, Val Loss: 0.2432
Epoch 7/110, Train Loss: 0.2563, Val Loss: 0.2130
Epoch 8/110, Train Loss: 0.1516, Val Loss: 0.1885
Epoch 9/110, Train Loss: 0.1352, Val Loss: 0.1738
Epoch 10/110, Train Loss: 0.1141, Val Loss: 0.1683
Epoch 11/110, Train Loss: 0.1252, Val Loss: 0.1638
Epoch 12/110, Train Loss: 0.1291, Val Loss: 0.1589
Epoch 13/110, Train Loss: 0.0928, Val Loss: 0.1535
Epoch 14/110, Train Loss: 0.1117, Val Loss: 0.1460
Epoch 15/110, Train Loss: 0.1142, Val Loss: 0.1419
Epoch 16/110, Train Loss: 0.1257, Val Loss: 0.1402
Epoch 17/110, Train Loss: 0.0996, Val Loss: 0.1379
Epoch 18/110, Train Loss: 0.1095, Val Loss: 0.1354
Epoch 19/110, Train Loss: 0.0951, Val Loss: 0.1336
Epoch 20/110, Train Loss: 0.0715, Val Loss: 0.1332
Epoch 21/110, Train Loss: 0.0810, Val Loss: 0.1325
Epoch 22/110, Train Loss: 0.0982, Val Loss: 0.1311
Epoch 23/110, Train Loss: 0.0781, Val Loss: 0.1293
Epoch 24/110, Train Loss: 0.0785, Val Loss: 0.1264
Epoch 25/110, Train Loss: 0.0730, Val Loss: 0.1234
Epoch 26/110, Train Loss: 0.0784, Val Loss: 0.1209
Epoch 27/110, Train Loss: 0.0970, Val Loss: 0.1192
Epoch 28/110, Train Loss: 0.0800, Val Loss: 0.1184
Epoch 29/110, Train Loss: 0.1036, Val Loss: 0.1185
Epoch 30/110, Train Loss: 0.0547, Val Loss: 0.1184
Epoch 31/110, Train Loss: 0.0763, Val Loss: 0.1175
Epoch 32/110, Train Loss: 0.0696, Val Loss: 0.1163
Epoch 33/110, Train Loss: 0.0725, Val Loss: 0.1152
Epoch 34/110, Train Loss: 0.0526, Val Loss: 0.1141
Epoch 35/110, Train Loss: 0.0589, Val Loss: 0.1131
Epoch 36/110, Train Loss: 0.0636, Val Loss: 0.1124
Epoch 37/110, Train Loss: 0.0656, Val Loss: 0.1116
Epoch 38/110, Train Loss: 0.0633, Val Loss: 0.1110
Epoch 39/110, Train Loss: 0.0767, Val Loss: 0.1106
Epoch 40/110, Train Loss: 0.0682, Val Loss: 0.1101
Epoch 41/110, Train Loss: 0.0765, Val Loss: 0.1097
Epoch 42/110, Train Loss: 0.0534, Val Loss: 0.1092
Epoch 43/110, Train Loss: 0.0774, Val Loss: 0.1088
Epoch 44/110, Train Loss: 0.0642, Val Loss: 0.1081
Epoch 45/110, Train Loss: 0.0600, Val Loss: 0.1075
Epoch 46/110, Train Loss: 0.0521, Val Loss: 0.1070
Epoch 47/110, Train Loss: 0.0664, Val Loss: 0.1067
Epoch 48/110, Train Loss: 0.0600, Val Loss: 0.1065
Epoch 49/110, Train Loss: 0.0687, Val Loss: 0.1061
Epoch 50/110, Train Loss: 0.0510, Val Loss: 0.1057
Epoch 51/110, Train Loss: 0.0543, Val Loss: 0.1053
Epoch 52/110, Train Loss: 0.0672, Val Loss: 0.1049
Epoch 53/110, Train Loss: 0.0690, Val Loss: 0.1048
Epoch 54/110, Train Loss: 0.0704, Val Loss: 0.1050
Epoch 55/110, Train Loss: 0.0666, Val Loss: 0.1052
Epoch 56/110, Train Loss: 0.0577, Val Loss: 0.1047
Epoch 57/110, Train Loss: 0.0537, Val Loss: 0.1039
Epoch 58/110, Train Loss: 0.0529, Val Loss: 0.1035
Epoch 59/110, Train Loss: 0.0481, Val Loss: 0.1033
Epoch 60/110, Train Loss: 0.0630, Val Loss: 0.1032
Epoch 61/110, Train Loss: 0.0670, Val Loss: 0.1030
Epoch 62/110, Train Loss: 0.0463, Val Loss: 0.1026
Epoch 63/110, Train Loss: 0.0507, Val Loss: 0.1025
Epoch 64/110, Train Loss: 0.0537, Val Loss: 0.1024
Epoch 65/110, Train Loss: 0.0745, Val Loss: 0.1021
Epoch 66/110, Train Loss: 0.0469, Val Loss: 0.1019
Epoch 67/110, Train Loss: 0.0655, Val Loss: 0.1017
Epoch 68/110, Train Loss: 0.0541, Val Loss: 0.1020
Epoch 69/110, Train Loss: 0.0704, Val Loss: 0.1020
Epoch 70/110, Train Loss: 0.0689, Val Loss: 0.1017
Epoch 71/110, Train Loss: 0.0632, Val Loss: 0.1019
Epoch 72/110, Train Loss: 0.0604, Val Loss: 0.1018
Epoch 73/110, Train Loss: 0.0523, Val Loss: 0.1013
Epoch 74/110, Train Loss: 0.0571, Val Loss: 0.1005
Epoch 75/110, Train Loss: 0.0597, Val Loss: 0.1005
Epoch 76/110, Train Loss: 0.0501, Val Loss: 0.1018
Epoch 77/110, Train Loss: 0.0538, Val Loss: 0.1026
Epoch 78/110, Train Loss: 0.0451, Val Loss: 0.1015
Epoch 79/110, Train Loss: 0.0512, Val Loss: 0.1005
Epoch 80/110, Train Loss: 0.0477, Val Loss: 0.1000
Epoch 81/110, Train Loss: 0.0453, Val Loss: 0.0999
Epoch 82/110, Train Loss: 0.0554, Val Loss: 0.1005
Epoch 83/110, Train Loss: 0.0440, Val Loss: 0.1012
Epoch 84/110, Train Loss: 0.0668, Val Loss: 0.1012
Epoch 85/110, Train Loss: 0.0496, Val Loss: 0.1003
Epoch 86/110, Train Loss: 0.0462, Val Loss: 0.1012
Epoch 87/110, Train Loss: 0.0592, Val Loss: 0.1032
Epoch 88/110, Train Loss: 0.0506, Val Loss: 0.1009
Epoch 89/110, Train Loss: 0.0537, Val Loss: 0.0995
Epoch 90/110, Train Loss: 0.0479, Val Loss: 0.0997
Epoch 91/110, Train Loss: 0.0530, Val Loss: 0.1003
Epoch 92/110, Train Loss: 0.0648, Val Loss: 0.1006
Epoch 93/110, Train Loss: 0.0399, Val Loss: 0.1011
Epoch 94/110, Train Loss: 0.0439, Val Loss: 0.1012
Epoch 95/110, Train Loss: 0.0438, Val Loss: 0.1012
Epoch 96/110, Train Loss: 0.0592, Val Loss: 0.1013
Epoch 97/110, Train Loss: 0.0431, Val Loss: 0.1018
Epoch 98/110, Train Loss: 0.0464, Val Loss: 0.1020
Epoch 99/110, Train Loss: 0.0554, Val Loss: 0.1018
Epoch 100/110, Train Loss: 0.0455, Val Loss: 0.1017
Epoch 101/110, Train Loss: 0.0506, Val Loss: 0.1020
Epoch 102/110, Train Loss: 0.0371, Val Loss: 0.1022
Epoch 103/110, Train Loss: 0.0440, Val Loss: 0.1024
Epoch 104/110, Train Loss: 0.0490, Val Loss: 0.1024
Epoch 105/110, Train Loss: 0.0514, Val Loss: 0.1022
Epoch 106/110, Train Loss: 0.0455, Val Loss: 0.1018
Epoch 107/110, Train Loss: 0.0444, Val Loss: 0.1017
Epoch 108/110, Train Loss: 0.0419, Val Loss: 0.1017
Epoch 109/110, Train Loss: 0.0645, Val Loss: 0.1018
Epoch 110/110, Train Loss: 0.0398, Val Loss: 0.1020
Model saved as: /home/samuele/MLproject/Presentation/AMPM_presentation.ptm
Test Loss: 0.0573
Results saved to /home/samuele/MLproject/Presentation/results.json
  Component  Sum of Squared Differences  Max absolute error  Relative error
0         x                       26.36                0.46           68.10
1         y                       20.37                0.39           24.12
2         z                        4.59                0.12             NaN
3      roll                        5.23                0.06             NaN
4     pitch                        4.64                0.07             NaN
5       yaw                       39.63                2.59           40.55
6       lin                       21.80                0.50            8.84
7       ang                       58.42                3.89          580.49
      T_x   T_y  T_z  T_roll  T_pitch  T_yaw  T_lin  T_ang
186 -1.16 -0.37  0.0     0.0      0.0   0.18   1.08  -0.02
187 -1.20 -0.36  0.0     0.0      0.0   0.18   1.08   0.02
188 -1.24 -0.36  0.0     0.0      0.0   0.18   1.08  -0.01
190 -1.33 -0.36  0.0     0.0      0.0   0.18   1.08  -0.02
191 -1.37 -0.36  0.0     0.0      0.0   0.18   1.08  -0.02
185 -1.12 -0.37  0.0     0.0      0.0   0.18   1.08  -0.02
189 -1.29 -0.36  0.0     0.0      0.0   0.18   1.08  -0.02
43   0.52  0.25  0.0     0.0      0.0  -1.57   0.56  -0.02
42   0.55  0.28  0.0     0.0      0.0  -1.58   0.56  -0.02
41   0.58  0.31  0.0     0.0      0.0  -1.58   0.56  -0.01
44   0.49  0.21  0.0     0.0      0.0  -1.57   0.56  -0.02
40   0.61  0.35  0.0     0.0      0.0  -1.58   0.56   0.00
      T_x   T_y  T_z  T_roll  T_pitch  T_yaw  T_lin  T_ang
27  -0.04 -1.95  0.0     0.0      0.0   0.42   1.08  -3.54
61  -0.04 -0.37  0.0     0.0      0.0  -1.54   0.56   4.14
31  -0.18 -2.06  0.0     0.0      0.0   2.41   1.08  -0.19
179 -0.87 -0.38  0.0     0.0      0.0   0.18   1.08  -0.06
165 -0.30 -0.33  0.0     0.0      0.0  -0.04   1.08   1.41
168 -0.42 -0.30  0.0     0.0      0.0  -2.38   1.08   0.15
4   -0.02 -0.36  0.0     0.0      0.0   1.03   1.08  -3.39
192 -1.41 -0.36  0.0     0.0      0.0  -2.40   1.08  -0.02
193 -1.45 -0.36  0.0     0.0      0.0  -2.40   1.08  -0.02
160 -0.13 -0.53  0.0     0.0      0.0   0.10   1.08  -0.98
5    0.01 -0.40  0.0     0.0      0.0   0.72   1.08  -1.59
194 -1.49 -0.36  0.0     0.0      0.0  -2.40   1.08  -0.02
