{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf5cd79-1804-4b0e-af59-f85dabc04999",
   "metadata": {},
   "source": [
    "We want to train a motion prediction model, which takes the 6D-pose of an object(in our case a robot) and it's velocity(linear, angular), and uses this information to predict the position of the object a few seconds ahead. So the model observes, e.g. the last 10 seconds of a movement and creates a prediction based on this time window. The prediction is one timestep, so 1 second, which is the timestep that comes after the last 10 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996c9c9c-8bce-45fb-8d09-06b839d9372b",
   "metadata": {},
   "source": [
    "# The LSTM\n",
    "The model we chose to use for our project is the LSTM. The LSTM is a model able to capture long-term dependencies, as the name suggest (Long-Short Term Memory), making it ideal for sequence prediction and, in our case, motion forecasting. \\\n",
    "The principle of the LSTM is to deal with the vanishing / exploding gradient problem of RNNs by saving the long-term memory and the short-term memory into two different states; the long-term memory is saved in the cell state (c_t), while the short-term memory is saved in the hidden state (h_t).\n",
    "![alt text](LSTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7479301b-3e23-41ea-9e7a-d68be4064628",
   "metadata": {},
   "source": [
    "## The LSTM cell\n",
    "The LSTM cell is called a \"gated structure\"; this is beacuse each cell has three gates, called the forget gate, the input gate and the output gate\n",
    "![alt text](LSTM_Cell.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc32f9cb-bc7a-4c71-9a3a-1c7900c80d18",
   "metadata": {},
   "source": [
    "### The forget gate\n",
    "The forget gate controls how much of the long-term memory we keep by passing the current input through a sigmoid function together with the hidden layer and bias, and then multiplying it by the previous cell state c_t-1. A smaller value means less relevance of the past memory, while a bigger value means more relevance. In other words, the forget gate decides what to delete from the past\n",
    "![alt text](ForgetGate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa1cc8f-ed1e-4528-90e9-65894a7734c2",
   "metadata": {},
   "source": [
    "### The input gate\n",
    "The input gate decides how much of the current input and hidden state will influence the future long-term memory; in other words, decides what to add to the memory from the present.\n",
    "![alt text](InputGate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52154ea1-7d48-4e6e-bb5a-1020396a8b27",
   "metadata": {},
   "source": [
    "### The output gate\n",
    "The output gate takes the updated cell state (C_t), applies a tanh⁡ function to scale its values between −1 and 1, and then multiplies this by o_t (the output gate's activation vector). This produces the hidden state. The hidden state (h_t) represents the short-term memory that is immediately relevant for making predictions or decisions at the current time step. \\\n",
    "In other words, the output gate decides how much of the current memory should be shared as hidden state.\n",
    "![alt text](OutputGate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f839b1-23a2-4222-a4f5-c2f2a6b50be1",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7530893c-3aff-4d37-8e6c-0b4f4fa6e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import math\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec3f1081-cef3-42f9-9bf1-aff4086b0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTM(nn.Module):\n",
    "    def __init__(self, input_sz, hidden_sz):\n",
    "        super().__init__()\n",
    "        self.input_sz = input_sz\n",
    "        self.hidden_size = hidden_sz\n",
    "\n",
    "        # Projection layer to adjust input to hidden size to handle any input size\n",
    "        self.input_projection = nn.Linear(input_sz, hidden_sz)\n",
    "\n",
    "        self.W = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz * 4)) # Input weights: [U_i, U_o, U_c, U_f]\n",
    "        self.U = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz * 4)) # Hidden state weights: [W_i, W_o, W_c, W_f]\n",
    "        self.bias = nn.Parameter(torch.Tensor(hidden_sz * 4)) # Biases: [b_i, b_o, b_c, b_f]\n",
    "        self.init_weights()\n",
    "\n",
    "        # FUlly connected layer to original input size for making predictions \n",
    "        self.fc = nn.Linear(hidden_sz, input_sz)\n",
    "\n",
    "    def forward(self, x, init_states=None):\n",
    "        bs, seq_sz, input_features = x.size() # Unpack x to batch size, sequence size (time steps), input features\n",
    "\n",
    "        # Project input to hidden size\n",
    "        x_projected = self.input_projection(x)\n",
    "\n",
    "        hidden_seq = []\n",
    "        if init_states is None:\n",
    "            h_t, c_t = (torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "                        torch.zeros(bs, self.hidden_size).to(x.device))\n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "\n",
    "        HS = self.hidden_size \n",
    "        for t in range(seq_sz): # For each time step t:\n",
    "            x_t = x_projected[:, t, :] # We take the curret input\n",
    "            # batch the computations into a single matrix multiplication\n",
    "            gates = x_t @ self.W + h_t @ self.U + self.bias\n",
    "            i_t, f_t, g_t, o_t = (\n",
    "                torch.sigmoid(gates[:, :HS]), # input\n",
    "                torch.sigmoid(gates[:, HS:HS*2]), # forget\n",
    "                torch.tanh(gates[:, HS*2:HS*3]),\n",
    "                torch.sigmoid(gates[:, HS*3:]), # output\n",
    "            )\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            hidden_seq.append(h_t.unsqueeze(0))\n",
    "\n",
    "        # Use the last hidden state for prediction\n",
    "        prediction = self.fc(h_t)\n",
    "\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "        return prediction, (h_t, c_t)\n",
    "\n",
    "    def init_weights(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51595c-5ad2-4bf0-906a-7f2f5d5cfa2d",
   "metadata": {},
   "source": [
    "# Training and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f370c8-45d3-4da1-9af0-83285df3962d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msamueleghizzo\u001b[0m (\u001b[33msamueleghizzo-university-of-klagenfurt\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/samuele/MLproject/Presentation/wandb/run-20250206_191805-536t3z21</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/samueleghizzo-university-of-klagenfurt/AMPM/runs/536t3z21' target=\"_blank\">fresh-puddle-4</a></strong> to <a href='https://wandb.ai/samueleghizzo-university-of-klagenfurt/AMPM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/samueleghizzo-university-of-klagenfurt/AMPM' target=\"_blank\">https://wandb.ai/samueleghizzo-university-of-klagenfurt/AMPM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/samueleghizzo-university-of-klagenfurt/AMPM/runs/536t3z21' target=\"_blank\">https://wandb.ai/samueleghizzo-university-of-klagenfurt/AMPM/runs/536t3z21</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/samueleghizzo-university-of-klagenfurt/AMPM/runs/536t3z21?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f98b2dbb6d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"AMPM\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"architecture\": \"LSTM\",\n",
    "    \"dataset\": \"Self-collected, dataset6\",\n",
    "    \"epochs\": 110,\n",
    "    \"hidden_size\": 64,\n",
    "    \"normalization\": \"Standardized\",\n",
    "    \"batch_size\": 32\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edd52314-0a1b-4e92-99ae-60167531c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=200):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # Merge `num_windows` with `batch_size`\n",
    "            bs, nw, seq_len, feature_dim = X_batch.shape\n",
    "            # print(\"X_batch shape before merging: \", X_batch.shape)\n",
    "            X_batch = X_batch.view(bs * nw, seq_len, feature_dim)\n",
    "            # print(\"X_batch shape after merging: \", X_batch.shape)\n",
    "\n",
    "            # Adjust y_batch accordingly\n",
    "            y_batch = y_batch.view(bs * nw, -1)\n",
    "\n",
    "            # Pass reshaped inputs to the model\n",
    "            output, _ = model(X_batch)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(output, y_batch)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        wandb.log({\"Train loss\": train_loss})\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "               \n",
    "                bs, nw, seq_len, feature_dim = X_batch.shape\n",
    "                X_batch = X_batch.view(bs * nw, seq_len, feature_dim)\n",
    "\n",
    "                y_batch = y_batch.view(bs * nw, -1)\n",
    "\n",
    "                output, _ = model(X_batch)\n",
    "               \n",
    "                loss = criterion(output, y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Apply scheduler step to reduce learning rate\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        wandb.log({\"Val loss\": val_loss})\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae81ca-c457-43d0-8ec9-d1f76d38c5c2",
   "metadata": {},
   "source": [
    "# Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aabb772-da9f-482e-b36f-75051be4725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(filepath):\n",
    "    tensor_files = [os.path.join(root, file) for root, dirs, files in os.walk(filepath) for file in files if file.endswith('tensor_data.npy')]\n",
    "\n",
    "    print(f\"Found {len(tensor_files)} tensor files\")\n",
    "\n",
    "    sequences = []\n",
    "    sequence_lengths = []\n",
    "\n",
    "    for file_path in tensor_files:\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        movement_data = torch.tensor(data['data'], dtype=torch.float32)\n",
    "        movement_data = torch.cat((movement_data[:, :-2], movement_data[:, -1:]), dim=1)  # Remove second-to-last column, this was a redundant feature\n",
    "        sequence_lengths.append(movement_data.shape[0])\n",
    "        sequences.append(movement_data)\n",
    "        #print(movement_data.shape)\n",
    "    \n",
    "    print(f\"Loaded {len(sequences)} sequences with varying lengths.\")\n",
    "    return sequences, sequence_lengths\n",
    "\n",
    "# filtering out sequences with less than 50 timesteps\n",
    "def filter_small_sequences(sequences, sequence_lengths, min_length=50):\n",
    "    filtered_sequences = []\n",
    "    filtered_sequence_lengths = []\n",
    "    \n",
    "    for seq_idx, sequence in enumerate(sequences):\n",
    "        if sequence_lengths[seq_idx] >= min_length:\n",
    "            filtered_sequences.append(sequence)\n",
    "            filtered_sequence_lengths.append(sequence_lengths[seq_idx])\n",
    "    \n",
    "    print(f\"Filtered out {len(sequences) - len(filtered_sequences)} sequences with less than {min_length} timesteps.\")\n",
    "    return filtered_sequences, filtered_sequence_lengths\n",
    "\n",
    "# shortening all sequences, such that they are all of length 50\n",
    "def shorten_sequences(filtered_sequences, filtered_sequence_lengths, max_length=50):\n",
    "    cut_sequences = []\n",
    "    cut_sequence_lengths = []\n",
    "\n",
    "    for seq_idx, sequence in enumerate(filtered_sequences):\n",
    "        if filtered_sequence_lengths[seq_idx] > max_length and filtered_sequence_lengths[seq_idx] < 2*max_length:\n",
    "            cut_sequences.append(sequence[:max_length])\n",
    "            cut_sequence_lengths.append(max_length)\n",
    "        else:\n",
    "            sequence = sequence[:2*max_length]\n",
    "            t1 = sequence[:max_length]\n",
    "            t2 = sequence[max_length:]\n",
    "            cut_sequences.append(t1)\n",
    "            cut_sequences.append(t2)\n",
    "            cut_sequence_lengths.append(max_length)\n",
    "            cut_sequence_lengths.append(max_length)\n",
    "\n",
    "    return cut_sequences, cut_sequence_lengths\n",
    "\n",
    "# apply sliding windows to create input-output pairs for the LSTM\n",
    "def prepare_lstm_dataset(movement_sequences, sequence_lengths, window_size=10):\n",
    "    X, y = [], []\n",
    "\n",
    "    for seq_idx, sequence in enumerate(movement_sequences):\n",
    "        seq_length = sequence_lengths[seq_idx]\n",
    "\n",
    "        X_sequence = []\n",
    "        y_sequence = []\n",
    "        # added try-except, because one sequence gave an index out of bounds error, which didn't make sense\n",
    "        try:\n",
    "            for i in range(seq_length - window_size):\n",
    "                X_sequence.append(sequence[i:i+window_size])\n",
    "                y_sequence.append(sequence[i+window_size])\n",
    "        \n",
    "            X.append(torch.stack(X_sequence))\n",
    "            y.append(torch.stack(y_sequence))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in sequence {seq_idx}: {e}\")\n",
    "            print(f\"Sequence length: {seq_length}, Sequence shape: {sequence.shape}\")\n",
    "\n",
    "\n",
    "    print(f\"Prepared {len(X)} input sequences for training.\")\n",
    "    return X, y\n",
    "\n",
    "def standardize_data(X, y):\n",
    "    X_all = torch.cat([x.flatten(0, 1) for x in X], dim=0)\n",
    "    \n",
    "    mean = X_all.mean(dim=0, keepdim=True)\n",
    "    std = X_all.std(dim=0, keepdim=True)\n",
    "    \n",
    "    std[std == 0] = 1  # avoiding NaNs\n",
    "    X_standardized = [(x - mean) / std for x in X]\n",
    "    y_standardized = [(yy - mean) / std for yy in y]\n",
    "    \n",
    "    return X_standardized, y_standardized\n",
    "\n",
    "def split_sequences(sequences, test_size=0.1, val_size=0.1):\n",
    "    # Split sequences into train+val and test\n",
    "    X_train_val, X_test = train_test_split(sequences, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Split the train+val into train and validation\n",
    "    X_train, X_val = train_test_split(X_train_val, test_size=val_size / (1 - test_size), random_state=42)\n",
    "    \n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "def main():\n",
    "    filepath = 'catkin_ws/src/datasetcreator/src/runs_new'\n",
    "    sequences, sequence_lengths = load_data(filepath)\n",
    "    #print(sequences[0].shape)\n",
    "    #print(min(sequence_lengths))\n",
    "    #print(max(sequence_lengths))\n",
    "\n",
    "    filtered_sequences, filtered_sequence_lengths = filter_small_sequences(sequences, sequence_lengths, min_length=50)\n",
    "    print(\"Filtered sequences: \", len(filtered_sequences))\n",
    "    print(\"Minimum length after filtering: \", min(filtered_sequence_lengths))\n",
    "\n",
    "    cut_sequences, cut_sequence_lengths = shorten_sequences(filtered_sequences, filtered_sequence_lengths, max_length=50)\n",
    "    print(\"Shortened sequences: \", len(cut_sequences))\n",
    "    print(\"Minimum length after shortening: \", min(cut_sequence_lengths))\n",
    "    #print(max(cut_sequence_lengths))\n",
    "\n",
    "    #print(cut_sequences)\n",
    "    #print(cut_sequence_lengths)\n",
    "    X, y = prepare_lstm_dataset(cut_sequences, cut_sequence_lengths, window_size=10)\n",
    "\n",
    "    X_stand, y_stand = standardize_data(X, y)\n",
    "\n",
    "    X_train_seq, X_val_seq, X_test_seq = split_sequences(list(zip(X_stand, y_stand)))\n",
    "\n",
    "    X_train, y_train = zip(*X_train_seq)\n",
    "    X_val, y_val = zip(*X_val_seq)\n",
    "    X_test, y_test = zip(*X_test_seq)\n",
    "\n",
    "    print(f\"X_train: {len(X_train)}, X_val: {len(X_val)}, X_test: {len(X_test)}\")\n",
    "    print(f\"y_train: {len(y_train)}, y_val: {len(y_val)}, y_test: {len(y_test)}\")\n",
    "\n",
    "    torch.save({\n",
    "        'X_train': X_train, 'X_val': X_val, 'X_test': X_test,\n",
    "        'y_train': y_train, 'y_val': y_val, 'y_test': y_test\n",
    "    }, 'Datasets/lstm_dataset6.pt')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f1efd-e284-4c05-8d61-175c320ab0ee",
   "metadata": {},
   "source": [
    "![Video of how the dataset was created](gazebo.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4174918-b7d1-464b-a67e-d9a2c2bbcb02",
   "metadata": {},
   "source": [
    "# Loading data and Custom Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec8371dc-412e-464e-8d80-0e6118dbd6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    data = torch.load(data_path, weights_only=True)\n",
    "    X_train, y_train = data['X_train'], data['y_train']\n",
    "    X_val, y_val = data['X_val'], data['y_val']\n",
    "    X_test, y_test = data['X_test'], data['y_test']\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27eaa8a7-59fe-43ba-ae6a-ee1193ef3a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X  \n",
    "        self.y = y  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa1238-22e2-45fa-ae7d-b0d847bf5102",
   "metadata": {},
   "source": [
    "# Let's look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30d99afe-7ef9-43c3-95ad-0dc47fdd729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0890d8f8-2c5a-4c7d-a39a-35ede9d8439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'lstm_dataset6.pt'\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de24909f-f953-42fc-99f1-319fe77d9b4f",
   "metadata": {},
   "source": [
    "## X_train and y_train\n",
    "X_train and y_train each contain 41 elements, which are the number of movements recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "544d5f06-6d60-4e36-8b6d-88b93f66d9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movements inside X_train: 41\n",
      "Number of movements inside y_train: 41\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of movements inside X_train:\", len(X_train))\n",
    "print(\"Number of movements inside y_train:\", len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86eaa49-6aa3-4caa-8a7d-95546509572e",
   "metadata": {},
   "source": [
    "Each of this movement is then split upon 40 further time series, each time series being 10 time steps and 8 features in case of X_train and only one time step in case of y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41271bdf-6346-4119-b7b3-0cabc83cdcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([40, 10, 8])\n",
      "y_train shape: torch.Size([40, 8])\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train[0].shape)\n",
    "print(\"y_train shape:\", y_train[0].shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07010842-6f2a-4b5d-822e-af613183f40a",
   "metadata": {},
   "source": [
    "### Single movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30c76255-bb35-477a-baa6-710fffedc7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single X_train tensor:\n",
      "tensor([[-0.0402, -0.3652,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],\n",
      "        [-0.0290, -0.3652,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],\n",
      "        [ 0.0066, -0.3655,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825,  0.0123],\n",
      "        [ 0.0480, -0.3656,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0481],\n",
      "        [ 0.0895, -0.3652,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],\n",
      "        [ 0.1310, -0.3650,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],\n",
      "        [ 0.1724, -0.3649,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],\n",
      "        [ 0.2139, -0.3648,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],\n",
      "        [ 0.2554, -0.3648,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238],\n",
      "        [ 0.2969, -0.3648,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238]])\n",
      "\n",
      "Corresponding y_train tensor:\n",
      "tensor([ 0.3383, -0.3648,  0.0000,  0.0000,  0.0000,  0.1534,  1.0825, -0.0238])\n"
     ]
    }
   ],
   "source": [
    "single_x_tensor = X_train[0][0]\n",
    "print(\"\\nSingle X_train tensor:\")\n",
    "print(single_x_tensor)\n",
    "\n",
    "single_y_tensor = y_train[0][0]\n",
    "print(\"\\nCorresponding y_train tensor:\")\n",
    "print(single_y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e616542-24d0-46ed-9070-b6330e134a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train tensor as table:\n",
      "          x         y    z  roll  pitch       yaw  linear_velocity  \\\n",
      "0 -0.040197 -0.365190  0.0   0.0    0.0  0.153439         1.082531   \n",
      "1 -0.028958 -0.365195  0.0   0.0    0.0  0.153439         1.082531   \n",
      "2  0.006575 -0.365532  0.0   0.0    0.0  0.153439         1.082531   \n",
      "3  0.048038 -0.365624  0.0   0.0    0.0  0.153439         1.082531   \n",
      "4  0.089508 -0.365212  0.0   0.0    0.0  0.153439         1.082531   \n",
      "5  0.130979 -0.365017  0.0   0.0    0.0  0.153439         1.082531   \n",
      "6  0.172448 -0.364908  0.0   0.0    0.0  0.153439         1.082531   \n",
      "7  0.213917 -0.364838  0.0   0.0    0.0  0.153439         1.082531   \n",
      "8  0.255389 -0.364792  0.0   0.0    0.0  0.153439         1.082531   \n",
      "9  0.296858 -0.364766  0.0   0.0    0.0  0.153439         1.082531   \n",
      "\n",
      "   angular_velocity  \n",
      "0         -0.023835  \n",
      "1         -0.023835  \n",
      "2          0.012337  \n",
      "3         -0.048119  \n",
      "4         -0.023835  \n",
      "5         -0.023835  \n",
      "6         -0.023835  \n",
      "7         -0.023835  \n",
      "8         -0.023835  \n",
      "9         -0.023835  \n",
      "\n",
      "y_train tensor as table:\n",
      "          x         y    z  roll  pitch       yaw  linear_velocity  \\\n",
      "0  0.338328 -0.364765  0.0   0.0    0.0  0.153439         1.082531   \n",
      "\n",
      "   angular_velocity  \n",
      "0         -0.023835  \n"
     ]
    }
   ],
   "source": [
    "columns = ['x', 'y', 'z', 'roll', 'pitch', 'yaw', 'linear_velocity', 'angular_velocity']\n",
    "\n",
    "single_x_np = single_x_tensor.numpy()\n",
    "single_y_np = single_y_tensor.numpy()\n",
    "\n",
    "df_x = pd.DataFrame(single_x_np, columns=columns)\n",
    "\n",
    "df_y = pd.DataFrame([single_y_np], columns=columns)\n",
    "\n",
    "print(\"X_train tensor as table:\")\n",
    "print(df_x)\n",
    "print(\"\\ny_train tensor as table:\")\n",
    "print(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00081e26-a188-4a53-b7c9-c8c852d034b1",
   "metadata": {},
   "source": [
    "## X/y_val, X/y_test\n",
    "The valuation and test data are done similary, with the only difference to be 6 movements for valuation and 6 movements for test. Therefore we have a data split of 77%-11%-11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9335e1a6-56e6-46ae-bda1-8864a0d82bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movements inside X_val: 6\n",
      "Number of movements inside y_val: 6\n",
      "X_val shape: torch.Size([40, 10, 8])\n",
      "y_val shape: torch.Size([40, 8])\n",
      "Number of movements inside X_test: 6\n",
      "Number of movements inside y_test: 6\n",
      "X_test shape: torch.Size([40, 10, 8])\n",
      "y_test shape: torch.Size([40, 8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of movements inside X_val:\", len(X_val))\n",
    "print(\"Number of movements inside y_val:\", len(y_val))\n",
    "print(\"X_val shape:\", X_val[0].shape)\n",
    "print(\"y_val shape:\", y_val[0].shape)\n",
    "print(\"Number of movements inside X_test:\", len(X_test))\n",
    "print(\"Number of movements inside y_test:\", len(y_test))\n",
    "print(\"X_test shape:\", X_test[0].shape)\n",
    "print(\"y_test shape:\", y_test[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3be846-b260-48fb-94ff-c21106b6abd6",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e236ada-58d5-4098-b126-883cb99d836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = CustomLSTM(input_sz=8, hidden_sz=64).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=0.00000000001, verbose=True)\n",
    "\n",
    "    data_path = 'lstm_dataset6.pt'\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_data(data_path)\n",
    "\n",
    "    train_dataset = CustomDataset(X_train, y_train)\n",
    "    val_dataset = CustomDataset(X_val, y_val)\n",
    "    #test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_losses, val_losses = train(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=110)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    OUTPUT_DIR = '/home/samuele/MLproject/Presentation'\n",
    "\n",
    "    model_name = os.path.join(OUTPUT_DIR, 'AMPM_presentation' + '.ptm')\n",
    "    torch.save(model.state_dict(), model_name)\n",
    "    print('Model saved as: ' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad7196b9-30f2-42db-b95b-82e6b1f59157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuele/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 6050). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/samuele/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110, Train Loss: 0.6475, Val Loss: 0.5031\n",
      "Epoch 2/110, Train Loss: 0.4940, Val Loss: 0.4269\n",
      "Epoch 3/110, Train Loss: 0.4047, Val Loss: 0.3364\n",
      "Epoch 4/110, Train Loss: 0.3120, Val Loss: 0.3021\n",
      "Epoch 5/110, Train Loss: 0.2564, Val Loss: 0.2708\n",
      "Epoch 6/110, Train Loss: 0.2450, Val Loss: 0.2432\n",
      "Epoch 7/110, Train Loss: 0.2563, Val Loss: 0.2130\n",
      "Epoch 8/110, Train Loss: 0.1516, Val Loss: 0.1885\n",
      "Epoch 9/110, Train Loss: 0.1352, Val Loss: 0.1738\n",
      "Epoch 10/110, Train Loss: 0.1141, Val Loss: 0.1683\n",
      "Epoch 11/110, Train Loss: 0.1252, Val Loss: 0.1638\n",
      "Epoch 12/110, Train Loss: 0.1291, Val Loss: 0.1589\n",
      "Epoch 13/110, Train Loss: 0.0928, Val Loss: 0.1535\n",
      "Epoch 14/110, Train Loss: 0.1117, Val Loss: 0.1460\n",
      "Epoch 15/110, Train Loss: 0.1142, Val Loss: 0.1419\n",
      "Epoch 16/110, Train Loss: 0.1257, Val Loss: 0.1402\n",
      "Epoch 17/110, Train Loss: 0.0996, Val Loss: 0.1379\n",
      "Epoch 18/110, Train Loss: 0.1095, Val Loss: 0.1354\n",
      "Epoch 19/110, Train Loss: 0.0951, Val Loss: 0.1336\n",
      "Epoch 20/110, Train Loss: 0.0715, Val Loss: 0.1332\n",
      "Epoch 21/110, Train Loss: 0.0810, Val Loss: 0.1325\n",
      "Epoch 22/110, Train Loss: 0.0982, Val Loss: 0.1311\n",
      "Epoch 23/110, Train Loss: 0.0781, Val Loss: 0.1293\n",
      "Epoch 24/110, Train Loss: 0.0785, Val Loss: 0.1264\n",
      "Epoch 25/110, Train Loss: 0.0730, Val Loss: 0.1234\n",
      "Epoch 26/110, Train Loss: 0.0784, Val Loss: 0.1209\n",
      "Epoch 27/110, Train Loss: 0.0970, Val Loss: 0.1192\n",
      "Epoch 28/110, Train Loss: 0.0800, Val Loss: 0.1184\n",
      "Epoch 29/110, Train Loss: 0.1036, Val Loss: 0.1185\n",
      "Epoch 30/110, Train Loss: 0.0547, Val Loss: 0.1184\n",
      "Epoch 31/110, Train Loss: 0.0763, Val Loss: 0.1175\n",
      "Epoch 32/110, Train Loss: 0.0696, Val Loss: 0.1163\n",
      "Epoch 33/110, Train Loss: 0.0725, Val Loss: 0.1152\n",
      "Epoch 34/110, Train Loss: 0.0526, Val Loss: 0.1141\n",
      "Epoch 35/110, Train Loss: 0.0589, Val Loss: 0.1131\n",
      "Epoch 36/110, Train Loss: 0.0636, Val Loss: 0.1124\n",
      "Epoch 37/110, Train Loss: 0.0656, Val Loss: 0.1116\n",
      "Epoch 38/110, Train Loss: 0.0633, Val Loss: 0.1110\n",
      "Epoch 39/110, Train Loss: 0.0767, Val Loss: 0.1106\n",
      "Epoch 40/110, Train Loss: 0.0682, Val Loss: 0.1101\n",
      "Epoch 41/110, Train Loss: 0.0765, Val Loss: 0.1097\n",
      "Epoch 42/110, Train Loss: 0.0534, Val Loss: 0.1092\n",
      "Epoch 43/110, Train Loss: 0.0774, Val Loss: 0.1088\n",
      "Epoch 44/110, Train Loss: 0.0642, Val Loss: 0.1081\n",
      "Epoch 45/110, Train Loss: 0.0600, Val Loss: 0.1075\n",
      "Epoch 46/110, Train Loss: 0.0521, Val Loss: 0.1070\n",
      "Epoch 47/110, Train Loss: 0.0664, Val Loss: 0.1067\n",
      "Epoch 48/110, Train Loss: 0.0600, Val Loss: 0.1065\n",
      "Epoch 49/110, Train Loss: 0.0687, Val Loss: 0.1061\n",
      "Epoch 50/110, Train Loss: 0.0510, Val Loss: 0.1057\n",
      "Epoch 51/110, Train Loss: 0.0543, Val Loss: 0.1053\n",
      "Epoch 52/110, Train Loss: 0.0672, Val Loss: 0.1049\n",
      "Epoch 53/110, Train Loss: 0.0690, Val Loss: 0.1048\n",
      "Epoch 54/110, Train Loss: 0.0704, Val Loss: 0.1050\n",
      "Epoch 55/110, Train Loss: 0.0666, Val Loss: 0.1052\n",
      "Epoch 56/110, Train Loss: 0.0577, Val Loss: 0.1047\n",
      "Epoch 57/110, Train Loss: 0.0537, Val Loss: 0.1039\n",
      "Epoch 58/110, Train Loss: 0.0529, Val Loss: 0.1035\n",
      "Epoch 59/110, Train Loss: 0.0481, Val Loss: 0.1033\n",
      "Epoch 60/110, Train Loss: 0.0630, Val Loss: 0.1032\n",
      "Epoch 61/110, Train Loss: 0.0670, Val Loss: 0.1030\n",
      "Epoch 62/110, Train Loss: 0.0463, Val Loss: 0.1026\n",
      "Epoch 63/110, Train Loss: 0.0507, Val Loss: 0.1025\n",
      "Epoch 64/110, Train Loss: 0.0537, Val Loss: 0.1024\n",
      "Epoch 65/110, Train Loss: 0.0745, Val Loss: 0.1021\n",
      "Epoch 66/110, Train Loss: 0.0469, Val Loss: 0.1019\n",
      "Epoch 67/110, Train Loss: 0.0655, Val Loss: 0.1017\n",
      "Epoch 68/110, Train Loss: 0.0541, Val Loss: 0.1020\n",
      "Epoch 69/110, Train Loss: 0.0704, Val Loss: 0.1020\n",
      "Epoch 70/110, Train Loss: 0.0689, Val Loss: 0.1017\n",
      "Epoch 71/110, Train Loss: 0.0632, Val Loss: 0.1019\n",
      "Epoch 72/110, Train Loss: 0.0604, Val Loss: 0.1018\n",
      "Epoch 73/110, Train Loss: 0.0523, Val Loss: 0.1013\n",
      "Epoch 74/110, Train Loss: 0.0571, Val Loss: 0.1005\n",
      "Epoch 75/110, Train Loss: 0.0597, Val Loss: 0.1005\n",
      "Epoch 76/110, Train Loss: 0.0501, Val Loss: 0.1018\n",
      "Epoch 77/110, Train Loss: 0.0538, Val Loss: 0.1026\n",
      "Epoch 78/110, Train Loss: 0.0451, Val Loss: 0.1015\n",
      "Epoch 79/110, Train Loss: 0.0512, Val Loss: 0.1005\n",
      "Epoch 80/110, Train Loss: 0.0477, Val Loss: 0.1000\n",
      "Epoch 81/110, Train Loss: 0.0453, Val Loss: 0.0999\n",
      "Epoch 82/110, Train Loss: 0.0554, Val Loss: 0.1005\n",
      "Epoch 83/110, Train Loss: 0.0440, Val Loss: 0.1012\n",
      "Epoch 84/110, Train Loss: 0.0668, Val Loss: 0.1012\n",
      "Epoch 85/110, Train Loss: 0.0496, Val Loss: 0.1003\n",
      "Epoch 86/110, Train Loss: 0.0462, Val Loss: 0.1012\n",
      "Epoch 87/110, Train Loss: 0.0592, Val Loss: 0.1032\n",
      "Epoch 88/110, Train Loss: 0.0506, Val Loss: 0.1009\n",
      "Epoch 89/110, Train Loss: 0.0537, Val Loss: 0.0995\n",
      "Epoch 90/110, Train Loss: 0.0479, Val Loss: 0.0997\n",
      "Epoch 91/110, Train Loss: 0.0530, Val Loss: 0.1003\n",
      "Epoch 92/110, Train Loss: 0.0648, Val Loss: 0.1006\n",
      "Epoch 93/110, Train Loss: 0.0399, Val Loss: 0.1011\n",
      "Epoch 94/110, Train Loss: 0.0439, Val Loss: 0.1012\n",
      "Epoch 95/110, Train Loss: 0.0438, Val Loss: 0.1012\n",
      "Epoch 96/110, Train Loss: 0.0592, Val Loss: 0.1013\n",
      "Epoch 97/110, Train Loss: 0.0431, Val Loss: 0.1018\n",
      "Epoch 98/110, Train Loss: 0.0464, Val Loss: 0.1020\n",
      "Epoch 99/110, Train Loss: 0.0554, Val Loss: 0.1018\n",
      "Epoch 100/110, Train Loss: 0.0455, Val Loss: 0.1017\n",
      "Epoch 101/110, Train Loss: 0.0506, Val Loss: 0.1020\n",
      "Epoch 102/110, Train Loss: 0.0371, Val Loss: 0.1022\n",
      "Epoch 103/110, Train Loss: 0.0440, Val Loss: 0.1024\n",
      "Epoch 104/110, Train Loss: 0.0490, Val Loss: 0.1024\n",
      "Epoch 105/110, Train Loss: 0.0514, Val Loss: 0.1022\n",
      "Epoch 106/110, Train Loss: 0.0455, Val Loss: 0.1018\n",
      "Epoch 107/110, Train Loss: 0.0444, Val Loss: 0.1017\n",
      "Epoch 108/110, Train Loss: 0.0419, Val Loss: 0.1017\n",
      "Epoch 109/110, Train Loss: 0.0645, Val Loss: 0.1018\n",
      "Epoch 110/110, Train Loss: 0.0398, Val Loss: 0.1020\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as: /home/samuele/MLproject/Presentation/AMPM_presentation.ptm\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc188c6c-3470-4df6-95f1-195a1bc94179",
   "metadata": {},
   "source": [
    "# Using the model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "688e7fbc-34f0-4ede-9d70-50d52f937236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a63ce610-cea5-4e49-abab-0aebce29e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion, device, feature_count=8):\n",
    "    model.eval() \n",
    "    test_loss = 0.0\n",
    "    all_y_truth = []\n",
    "    all_y_pred = []\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for X_batch, y_batch in test_loader:\n",
    "            \n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            bs, nw, seq_len, feature_dim = X_batch.shape\n",
    "            X_batch = X_batch.view(bs * nw, seq_len, feature_dim)\n",
    "            y_batch = y_batch.view(bs * nw, -1)\n",
    "\n",
    "            y_pred, _ = model(X_batch)\n",
    "\n",
    "            # Reshape predictions and ground truth to original shape for comparison\n",
    "            y_pred = y_pred.view(bs, nw, -1)\n",
    "            y_batch = y_batch.view(bs, nw, -1)\n",
    "\n",
    "            loss = criterion(y_pred[:, :, :feature_count], y_batch[:, :, :feature_count])\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            all_y_truth.append(y_batch[:, :, :feature_count].cpu())\n",
    "            all_y_pred.append(y_pred[:, :, :feature_count].cpu())\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "    # Convert predictions and truth to a format suitable for json\n",
    "    all_y_truth = torch.cat(all_y_truth, dim=0).numpy()\n",
    "    all_y_pred = torch.cat(all_y_pred, dim=0).numpy()\n",
    "\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "    mae = calculate_metrics(torch.tensor(all_y_pred), torch.tensor(all_y_truth))\n",
    "\n",
    "    save_results_as_json(all_y_truth, all_y_pred, \"/home/samuele/MLproject/Presentation/results.json\", mae, avg_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f7eb321-358f-4d3b-b6b9-a445ba7ccf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_as_json(truths, predictions, output_path, mae, avg_test_loss):\n",
    "    results = {\n",
    "        \"Metrics\": {\n",
    "            \"Mean Absolute Error (MAE)\": round(mae, 4),\n",
    "            \"Average Test Loss\": round(avg_test_loss, 4)\n",
    "        },\n",
    "        \"Predictions\": []\n",
    "    }\n",
    "\n",
    "    movement_id = 1\n",
    "    for truth, pred in zip(truths, predictions):\n",
    "        for t_row, p_row in zip(truth, pred):\n",
    "            differences = [round(float(t) - float(p), 2) for t, p in zip(t_row.tolist(), p_row.tolist())]\n",
    "            results[\"Predictions\"].append({\n",
    "                \"Movement\": movement_id,\n",
    "                \"Ground Truth\": [f\"{val:+.2f}\" for val in t_row.tolist()],\n",
    "                \"Prediction\": [f\"{val:+.2f}\" for val in p_row.tolist()],\n",
    "                \"Difference\": [f\"{val:+.2f}\" for val in differences]\n",
    "            })\n",
    "            movement_id += 1\n",
    "\n",
    "    with open(output_path, 'w') as json_file:\n",
    "        json.dump(results, json_file, indent=4)\n",
    "    print(f\"Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad167f6c-e245-436a-9676-db038635f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, truths):\n",
    "    abs_errors = torch.abs(predictions - truths)\n",
    "    squared_errors = abs_errors ** 2\n",
    "\n",
    "    mae = abs_errors.mean().item()\n",
    "    mse = squared_errors.mean().item()\n",
    "\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "147fddea-b893-4303-8dd6-fdd56c2d2b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = CustomLSTM(input_sz=8, hidden_sz=64).to(device)\n",
    "\n",
    "    model_path = 'AMPM_presentation.ptm'\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    data_path = 'lstm_dataset6.pt'\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = load_data(data_path)\n",
    "\n",
    "    test_dataset = CustomDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    test_model(model, test_loader, criterion, device, feature_count=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a03f980-ac7c-4e22-9478-53733f73e8e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0573\n",
      "Results saved to /home/samuele/MLproject/Presentation/results.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545925f5",
   "metadata": {},
   "source": [
    "# Model evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd988282-5c04-4941-a691-3a0ecb20f5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the JSON results file in a pandas DataFrame for easier calculations\n",
    "\n",
    "# Opening the JSON file\n",
    "with open('results.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the movements\n",
    "movements = data[\"Predictions\"]\n",
    "\n",
    "# Names of the columns\n",
    "columns = [\"T_x\", \"T_y\", \"T_z\", \"T_roll\", \"T_pitch\", \"T_yaw\", \"T_lin\", \"T_ang\", \n",
    "           \"P_x\", \"P_y\", \"P_z\", \"P_roll\", \"P_pitch\", \"P_yaw\", \"P_lin\", \"P_ang\", \n",
    "           \"D_x\", \"D_y\", \"D_z\", \"D_roll\", \"D_pitch\", \"D_yaw\", \"D_lin\", \"D_ang\"]\n",
    "\n",
    "# Creating the DataFrame\n",
    "rows = []\n",
    "for movement in movements:\n",
    "    row = movement[\"Ground Truth\"] + movement[\"Prediction\"] + movement[\"Difference\"]\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "df = df.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbaac1-05f8-4803-ab35-c7a0228c1a7d",
   "metadata": {},
   "source": [
    "## 1. Components of movements that are the best / worst predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98d08433-1b13-4417-8721-dc8308ff0a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Component  Sum of Squared Differences  Max absolute error  Relative error\n",
      "0         x                       26.36                0.46           68.10\n",
      "1         y                       20.37                0.39           24.12\n",
      "2         z                        4.59                0.12             NaN\n",
      "3      roll                        5.23                0.06             NaN\n",
      "4     pitch                        4.64                0.07             NaN\n",
      "5       yaw                       39.63                2.59           40.55\n",
      "6       lin                       21.80                0.50            8.84\n",
      "7       ang                       58.42                3.89          580.49\n"
     ]
    }
   ],
   "source": [
    "# Components of the movements\n",
    "components = [\"x\", \"y\", \"z\", \"roll\", \"pitch\", \"yaw\", \"lin\", \"ang\"]\n",
    "\n",
    "# Creating a DataFrame to show the results in a clear and synthetic way\n",
    "df_results = pd.DataFrame({\n",
    "    \"Component\": components,\n",
    "    \"Sum of Squared Differences\": [(df[f\"D_{c}\"].abs()).sum()  for c in components],\n",
    "    \"Max absolute error\": [df[f\"D_{c}\"].abs().max() for c in components],\n",
    "    \"Relative error\": [round((df[f\"D_{c}\"] / df[f\"T_{c}\"]).abs()[df[f\"T_{c}\"] != 0].mean()*100,2) for c in components],\n",
    "})\n",
    "\n",
    "# Printing the DataFrame\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2123ea-2e13-419e-ac16-b1b724bf1115",
   "metadata": {},
   "source": [
    "## 2. Best and worst predicted movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1de24e8-c984-4e05-ad29-9326e02ac4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      T_x   T_y  T_z  T_roll  T_pitch  T_yaw  T_lin  T_ang\n",
      "186 -1.16 -0.37  0.0     0.0      0.0   0.18   1.08  -0.02\n",
      "187 -1.20 -0.36  0.0     0.0      0.0   0.18   1.08   0.02\n",
      "188 -1.24 -0.36  0.0     0.0      0.0   0.18   1.08  -0.01\n",
      "190 -1.33 -0.36  0.0     0.0      0.0   0.18   1.08  -0.02\n",
      "191 -1.37 -0.36  0.0     0.0      0.0   0.18   1.08  -0.02\n",
      "185 -1.12 -0.37  0.0     0.0      0.0   0.18   1.08  -0.02\n",
      "189 -1.29 -0.36  0.0     0.0      0.0   0.18   1.08  -0.02\n",
      "43   0.52  0.25  0.0     0.0      0.0  -1.57   0.56  -0.02\n",
      "42   0.55  0.28  0.0     0.0      0.0  -1.58   0.56  -0.02\n",
      "41   0.58  0.31  0.0     0.0      0.0  -1.58   0.56  -0.01\n",
      "44   0.49  0.21  0.0     0.0      0.0  -1.57   0.56  -0.02\n",
      "40   0.61  0.35  0.0     0.0      0.0  -1.58   0.56   0.00\n"
     ]
    }
   ],
   "source": [
    "# Adding, for each movements, the sum of the absolute errors\n",
    "df[\"Total_Error\"] = df[[f\"D_{c}\" for c in components]].abs().sum(axis=1)\n",
    "\n",
    "# Keeping only the 5% best predicted movements (with the smaller total error)\n",
    "best_predicted = df.nsmallest(int(len(df) * 0.05), \"Total_Error\")\n",
    "print(best_predicted[[col for col in df.columns if col.startswith(\"T_\")]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12f98682-0700-4a98-aa6e-1ba3c900cefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      T_x   T_y  T_z  T_roll  T_pitch  T_yaw  T_lin  T_ang\n",
      "27  -0.04 -1.95  0.0     0.0      0.0   0.42   1.08  -3.54\n",
      "61  -0.04 -0.37  0.0     0.0      0.0  -1.54   0.56   4.14\n",
      "31  -0.18 -2.06  0.0     0.0      0.0   2.41   1.08  -0.19\n",
      "179 -0.87 -0.38  0.0     0.0      0.0   0.18   1.08  -0.06\n",
      "165 -0.30 -0.33  0.0     0.0      0.0  -0.04   1.08   1.41\n",
      "168 -0.42 -0.30  0.0     0.0      0.0  -2.38   1.08   0.15\n",
      "4   -0.02 -0.36  0.0     0.0      0.0   1.03   1.08  -3.39\n",
      "192 -1.41 -0.36  0.0     0.0      0.0  -2.40   1.08  -0.02\n",
      "193 -1.45 -0.36  0.0     0.0      0.0  -2.40   1.08  -0.02\n",
      "160 -0.13 -0.53  0.0     0.0      0.0   0.10   1.08  -0.98\n",
      "5    0.01 -0.40  0.0     0.0      0.0   0.72   1.08  -1.59\n",
      "194 -1.49 -0.36  0.0     0.0      0.0  -2.40   1.08  -0.02\n"
     ]
    }
   ],
   "source": [
    "# Keeping only the 5% worst predicted movements (with the higer total error)\n",
    "worst_predicted = df.nlargest(int(len(df) * 0.05), \"Total_Error\")\n",
    "print(worst_predicted[[col for col in df.columns if col.startswith(\"T_\")]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
